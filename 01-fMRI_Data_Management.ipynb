{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Management\n",
    "\n",
    "## Create a project folder\n",
    "\n",
    "Here is a recommended folder structure for your fMRI project. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "# An example folder structure for an fMRI project\n",
    "#\n",
    "# └── new_study_template               # the project name\n",
    "#     └── code\n",
    "#         └── analysis                 # analysis scripts folder\n",
    "#         └── preprocessing            # preprocessing scripts (heudiconv, mriqc, fmriprep)\n",
    "#         └── task                     # experimental task code\n",
    "#     └── data\n",
    "#         └── behavioral               # other behavioural data\n",
    "#         └── bids                     # this is where raw BIDS data will be saved by HeuDiConv\n",
    "#         └── dicom                    # raw dicoms copied from the scanner\n",
    "#         └── work                     # work (intermediate) files generated by fMRIprep and MRIQC\n",
    "#     └── doc                          # project notes and manuscript\n",
    "#     └── results                      #  \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can create it manually or you can use a simple `bash` script. Let's call it `create_study_template.sh`\n",
    "```bash\n",
    "#!/bin/bash\n",
    "new_study=$1 # this will be your project name that you pass to this script\n",
    "mkdir -p \"$new_study\"/{code/{analysis,preprocessing,task},data/{bids,dicom,work},doc,results}\n",
    "```\n",
    "\n",
    "To run this script, write the following in the terminal: `./create_study_template.sh FaceRecognition`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To initiate your analysis version control, you'd type the following in the terminal:\n",
    "```bash\n",
    "cd FaceRecognition\n",
    "git init\n",
    "```\n",
    "\n",
    "You don't need to track everything in your project. Mainly, you'd like to track your analysis scripts, and perhaps your documents. Basically, everything that is 'text based'. To exclude certain directories from being tracked, you can create a `.gitignore` file. \n",
    "\n",
    "Here I create a `.gitignore` file and specify that I don't want my 'data' and 'results' directories being tracked. \n",
    "```bash\n",
    "touch .gitignore\n",
    "echo data >>.gitignore\n",
    "echo results >>.gitignore\n",
    "```\n",
    "For basic `git` commands, see, for example, this [Git Cheat Sheet](https://about.gitlab.com/images/press/git-cheat-sheet.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution": "hidden"
   },
   "source": [
    "## Retrieving the DICOM files\n",
    "\n",
    "`DICOM` files are the raw imaging files that come from the MRI scanner. Usually they are stored on some MRI data server. At the CBU, each imaging project has a unique code. Knowing my project's code, I can locate the raw `DICOM` files on our server.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls -d /mridata/cbu/*_MR09029"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In may cases, you wouldn't even need to copy these data from the imaging server to your directory. You could only store the converted `NIfTI` files. But sometimes it is just more convenient to copy them over. **But don't foget to delete them from your folder once you have converted the data!** You can always retrieve the raw files from their original location.\n",
    "\n",
    "For our example study, only 16 of these folders (participants) have the complete data that we need. I have copied these to my `/data/dicom` folder. I used the following `bash` script for that:\n",
    "\n",
    "```bash\n",
    "#!/bin/bash\n",
    "set -eu\n",
    "\n",
    "sourcepath=\"/mridata/cbu/\"\n",
    "destpath=\"/imaging/correia/dace/training/summer-school/Example_v02/FaceRecognition/data/dicom/\"\n",
    "\n",
    "projectCode=\"MR09029\"\n",
    "CBUid=(\"CBU090942\" \"CBU090938\" \"CBU090964\" \"CBU090928\" \"CBU090931\" \"CBU090935\" \"CBU090970\" \"CBU090956\" \"CBU090958\" \"CBU090968\" \"CBU090957\" \"CBU090966\" \"CBU090951\" \"CBU090945\" \"CBU090962\" \"CBU090967\")\n",
    "nr=0\n",
    "for id in \"${CBUid[@]}\"; do\n",
    "    nr=$((nr + 1))\n",
    "    # change sub id to be 01 02 ...\n",
    "    newid=$(printf \"%02d\" \"$nr\")\n",
    "\n",
    "    source=\"$sourcepath\"\"$id\"_\"$projectCode\"\n",
    "    destination=\"$destpath\"\"$newid\"\n",
    "\n",
    "    srun -N1 -n1 -c1 cp -R \"$source\" \"$destination\" &\n",
    "    echo \"$source\"  copied\n",
    "    echo 'Remove 2 Dummy scans from each functional run ( 210-2=208 )!'\n",
    "done\n",
    "```\n",
    "\n",
    "In the script, I changed the subject ID's to be 01, 02 etc. It is not necessary to do so, but it just looks 'nicer', I think. And in this studie's version on OpenNeuro, subjects are numbered like that. Here I matched my subject ID's to the OpenNeuro version. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tree /imaging/correia/dace/training/summer-school/Example_v02/FaceRecognition/data/dicom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy scans\n",
    "\n",
    "When we start acquiring fMRI data, scanner needs some time to reach a steady state. Therefore a common practice is to dicard the first couple of volumes - **the dummy scans**. Often it is done at the scanner level and we never see these scans. But sometimes we need to discard them ourselves from the DICOM files that we get from the scanner. In this example case, we need to dicard the first two volumes from each functional run (2 dummy scans). \n",
    "\n",
    "You can exclude them at later stages of your analysis, but I find it less troublesome to exclude them already from the DICOM files. \n",
    "\n",
    "When excluding dummies, make sure you accordingly adjust our stimulus onset times!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brain Imaging Data Structure (BIDS)\n",
    "\n",
    "To proceed with analysis, we need to convert the `DICOMs` to `NIfTI` format and then organise all these files in a 'nice' way.\n",
    "\n",
    "[Brain Imaging Data Structure (**BIDS**)](https://bids-specification.readthedocs.io/en/stable/) is a a standard for organizing and describing neuroimaging (and behavioural) datasets. See [BIDS paper](https://doi.org/10.1038/sdata.2016.44) and http://bids.neuroimaging.io website for more information.\n",
    "\n",
    "How to get your DICOMs into NIfTI and into BIDS?\n",
    "\n",
    "Several tools exist. I will here demonstrate [HeudiConv](https://heudiconv.readthedocs.io/en/latest/index.html). \n",
    "\n",
    "`heudiconv` is a flexible `DICOM` converter for organizing brain imaging data into structured directory layouts.\n",
    "* It allows flexible directory layouts and naming schemes through customizable heuristics implementations\n",
    "* It only converts the necessary DICOMs, not everything in a directory\n",
    "* You can keep links to DICOM files in the participant layout\n",
    "* Using `dcm2niix` under the hood, it’s fast\n",
    "* It provides assistance in converting to `BIDS`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HeudiConv\n",
    "\n",
    "```\n",
    "pip install heudiconv==0.11.3\n",
    "conda install dcm2nii \n",
    "```\n",
    "(What's the difference between `pip` and `conda`, you wonder? [See here](https://pythonspeed.com/articles/conda-vs-pip/))\n",
    "\n",
    "Or use Docker or Singularity\n",
    "\n",
    "`heidiconv` involves 3 main steps:\n",
    "1. Discover what type of DICOM files you have\n",
    "2. Create a 'heuristics' for how to translate DICOMs into your desired layout (i.e., BIDS)\n",
    "3. Converts DICOMs to NIfTI and uses the heuristics file to accordingly organise the .nii.gz and their corresponding .json files. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DICOM discover"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`step01_heudiconv_dicom_discover.sh`\n",
    "```bash\n",
    "#!/bin/bash\n",
    "d_path=\"/imaging/correia/dace/training/summer-school/Example_v02/FaceRecognition/data/dicom/\"\n",
    "o_path=\"/imaging/correia/dace/training/summer-school/Example_v02/FaceRecognition/\"\n",
    "sid=\"01\"\n",
    "# -d, --dicom_dir_template\n",
    "# -o, --outdir\n",
    "# -f, --heuristic\n",
    "# -s, --subjects\n",
    "# -c, --converter\n",
    "# -b, --bids\n",
    "heudiconv \\\n",
    "    -d $d_path/{subject}/*/*/*.dcm \\\n",
    "    -o $o_path/data/work/dicom_discovery/ \\\n",
    "    -f convertall \\\n",
    "    -s $sid \\\n",
    "    -c none \\\n",
    "    -b --overwrite\n",
    "```\n",
    "`./step01_heudiconv_dicom_discover.sh`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Btw, you can also call `shell sctipts` from `Python`. See an example below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "pdir = \"/imaging/correia/dace/training/summer-school/Example_v02/FaceRecognition\"\n",
    "\n",
    "#subprocess.call(os.path.join(pdir, \"code/preprocessing/step01_heudiconv_dicom_discover.sh\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now navigate to the created output directory. In my case `/imaging/correia/dace/training/summer-school/Example_v02/FaceRecognition/data/work/dicom_discovery/`\n",
    "And there go to `.heudiconv/[sub-id]/info` and open `dicominfo.tsv` file.\n",
    "\n",
    "Or open it here, in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "infopath = os.path.join(pdir, \"data/work/dicom_discovery/.heudiconv/01/info\", \"dicominfo.tsv\")\n",
    "pd.read_csv(infopath, sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Heuristics file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`heudiconv_heuristic.py`\n",
    "\n",
    "```python\n",
    "import os\n",
    "\n",
    "def create_key(template, outtype=('nii.gz',), annotation_classes=None):\n",
    "    if template is None or not template:\n",
    "        raise ValueError('Template must be a valid format string')\n",
    "    return template, outtype, annotation_classes\n",
    "\n",
    "def infotodict(seqinfo):\n",
    "    # BIDS keys\n",
    "    anat = create_key('sub-{subject}/anat/sub-{subject}_acq-mprage_T1w')\n",
    "    fmap_mag = create_key('sub-{subject}/fmap/sub-{subject}_magnitude')\n",
    "    fmap_phase = create_key('sub-{subject}/fmap/sub-{subject}_phasediff')\n",
    "    func_task = create_key('sub-{subject}/func/sub-{subject}_task-facerecognition_run-0{item:01d}_bold')\n",
    "\n",
    "    info = {anat: [], fmap_mag: [], fmap_phase: [],\n",
    "            func_task: []}\n",
    "\n",
    "    for idx, s in enumerate(seqinfo):\n",
    "        # anat T1w\n",
    "        if (s.dim1 == 256) and (\"MPRAGE\" in s.protocol_name):\n",
    "            info[anat].append(s.series_id)\n",
    "        # Field map Magnitude\n",
    "        if (s.dim3 == 66) and ('FieldMapping' in s.protocol_name):\n",
    "            info[fmap_mag].append(s.series_id)\n",
    "        # Field map PhaseDiff\n",
    "        if (s.dim3 == 33) and ('FieldMapping' in s.protocol_name):\n",
    "            info[fmap_phase].append(s.series_id)        \n",
    "        # Functional Bold\n",
    "        if (s.dim1 == 64) and (s.dim4 > 100):\n",
    "            info[func_task].append(s.series_id)\n",
    "                \n",
    "    return info\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert DICOM to BIDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar as we did in DICOM discovery. But now we specify the heuristics file and the converter (*dcm2niix*), so that the files are actually converted. \n",
    "\n",
    "An example script for converting a single subject:\n",
    "\n",
    "`example_dicom2bids_single-subject.sh`\n",
    "\n",
    "```bash\n",
    "#!/bin/bash\n",
    "d_path=\"/imaging/correia/dace/training/summer-school/Example_v02/FaceRecognition/data/dicom/\"\n",
    "o_path=\"/imaging/correia/dace/training/summer-school/Example_v02/FaceRecognition/\"\n",
    "sid=\"01\"\n",
    "# -d, --dicom_dir_template\n",
    "# -o, --outdir\n",
    "# -f, --heuristic\n",
    "# -s, --subjects\n",
    "# -c, --converter\n",
    "# -b, --bids\n",
    "heudiconv \\\n",
    "    -d $d_path/{subject}/*/*/*.dcm \\\n",
    "    -o $o_path/data/bids/ \\\n",
    "    -f $o_path/code/preprocessing/heudiconv_heurisctic.py \\\n",
    "    -s $sid \\\n",
    "    -c dcm2niix \\\n",
    "    -b --overwrite\n",
    "```\n",
    "`./example_dicom2bids_single-subject.sh`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have many participants, then creating subject by subject sequentially is not very practical. Instead, you could create a `batch job` and convert all subjects at the same time. \n",
    "\n",
    "`step02_heudiconv_batch`\n",
    "```bash\n",
    "#!/bin/bash\n",
    "# ======================================================================\n",
    "# Dace Apšvalka (MRC CBU 2022)\n",
    "# ======================================================================\n",
    "set -eu\n",
    "\n",
    "# Project path needs to be specified when submitting the function\n",
    "PROJECT_PATH=${1}\n",
    "# Where the dicoms are located\n",
    "DICOM_PATH=\"${PROJECT_PATH}\"/data/dicom/\n",
    "# Where to output jobs\n",
    "JOB_DIR=\"$PROJECT_PATH\"/data/work/bids/jobs\n",
    "mkdir -p \"$JOB_DIR\"\n",
    "cd \"$JOB_DIR\"\n",
    "# Get the list of subject for this project\n",
    "# each subfolder in the dicom path\n",
    "SUBJECT_LIST=()\n",
    "for d in \"$DICOM_PATH\"*; do\n",
    "    sub_id=$(basename \"$d\")\n",
    "    SUBJECT_LIST+=(\"$sub_id\")\n",
    "done\n",
    "# Submit to the dicom2bids script as a job array on SLURM\n",
    "sbatch --array=0-$((${#SUBJECT_LIST[@]} - 1)) \"$PROJECT_PATH\"/code/preprocessing/step02_heudiconv_run.sh \"${PROJECT_PATH}\" \"${DICOM_PATH}\" \"${SUBJECT_LIST[@]}\"\n",
    "```\n",
    "\n",
    "The `batch job` calls and executes this script:\n",
    "\n",
    "`02_heudiconv_run.sh`\n",
    "```bash\n",
    "#!/bin/bash\n",
    "# ======================================================================\n",
    "# Dace Apšvalka (MRC CBU 2022)\n",
    "# ======================================================================\n",
    "set -eu\n",
    "\n",
    "# Project path needs to be specified when submitting the function\n",
    "PROJECT_PATH=${1}\n",
    "# Where the dicoms are located\n",
    "DICOM_PATH=${2}\n",
    "# where to output the data\n",
    "OUTDIR=\"$PROJECT_PATH\"/data/bids\n",
    "# All list items of the 3rd variable from batch-dicom2bids\n",
    "SUBJECT_LIST=(\"${@:3}\")\n",
    "# Index each subject per job array\n",
    "subject=${SUBJECT_LIST[${SLURM_ARRAY_TASK_ID}]}\n",
    "\n",
    "# Processing start time\n",
    "start=$(date +%s)\n",
    "# Write out the starting details\n",
    "date\n",
    "echo Submitted subject: \"${subject}\"\n",
    "echo DICOM path: \"$DICOM_PATH\"\"${subject}\"/\n",
    "\n",
    "# Do the conversion using heudiconv\n",
    "heudiconv \\\n",
    "    -d \"${DICOM_PATH}\"{subject}/*/*/*.dcm \\\n",
    "    -o \"${OUTDIR}\" \\\n",
    "    -f \"${PROJECT_PATH}\"/code/preprocessing/heudiconv_heurisctic.py \\\n",
    "    -s \"${subject}\" \\\n",
    "    -c dcm2niix \\\n",
    "    -b --overwrite\n",
    "\n",
    "# Procesing end time\n",
    "end=$(date +%s)\n",
    "# Write out the elapssed processing time\n",
    "echo Time elapsed: \"$(TZ=UTC0 printf '%(%H:%M:%S)T\\n' $((end - start)))\"\n",
    "```\n",
    "To run the `batch script`, you'd write in the terminal:\n",
    "\n",
    "`./step02_heudiconv_batch.sh /imaging/correia/dace/training/summer-school/Example_v02/FaceRecognition/`\n",
    "\n",
    "It tkes about 5 min to convert all my 16 subjects.\n",
    "\n",
    "------------\n",
    "<div style='background-color: yellow'>\n",
    "Inspect the output.   \n",
    "</div>\n",
    "\n",
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 'To Do' - additional information to check and add"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset description\n",
    "\n",
    "`dataset_description.json`\n",
    "\n",
    "We can get the information here: https://openneuro.org/datasets/ds000117/versions/1.0.5/file-display/dataset_description.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Participants\n",
    "\n",
    "`participants.json`\n",
    "\n",
    "Check and edit the information as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task information\n",
    "\n",
    "`task-facerecognition_bold.json`\n",
    "\n",
    "Could add full task name and a Cognitive Atlas ID if known. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Events\n",
    "You need to fill in your experiment trial onsets and durations. \n",
    "\n",
    "Here I retrieve the event timing information from the OpenNeuro version of this dataset. In this version, the dummy scans had been removed and timings adjusted accordingly. As I have also removed the dummy scans, I can use these timings without any further adjustement (well, some adjustments will be needed!). \n",
    "\n",
    "Here, to demonstrate that you can also edit and run `Matlab` ecripts from `VSCode`, is a `Matlab` script that I wrote to get the event information in my BIDS events files. \n",
    "\n",
    "You'd run this script from a terminal: `matlab2019a -batch \"step04_BIDS_copy_events\"`\n",
    "\n",
    "`MATLAB script`\n",
    "```C\n",
    "% Copy event information from Wakeman's ds000117 to my ExampleStudy\n",
    "clearvars\n",
    "source = '/imaging/correia/dace/training/summer-school/Wakeman-ds/ds000117';\n",
    "destination = '/imaging/correia/dace/training/summer-school/Example_v02/FaceRecognition/data/bids';\n",
    "nsub = 16;\n",
    "nrun = 9;\n",
    "\n",
    "for i = 1:nsub\n",
    "    sub = ['sub-' num2str(i,'%02.f')];\n",
    "    sourceDir = fullfile(source, sub, 'ses-mri', 'func');\n",
    "    sourceList = dir(fullfile(sourceDir, '*.tsv'));\n",
    "    \n",
    "    destDir = fullfile(destination, sub, 'func');\n",
    "    destList = dir(fullfile(destDir, '*.tsv'));\n",
    "    \n",
    "    for f = 1:nrun\n",
    "        f1 = fullfile(sourceList(f).folder, sourceList(f).name);\n",
    "        f2 = fullfile(destList(f).folder, destList(f).name);\n",
    "        copyfile(f1, f2, 'f');\n",
    "    end\n",
    "end\n",
    "```\n",
    "Later (in my analysis) I discovered, that I needed to make some amends to the copied events files. According to `BIDS` specification for [Task Events](https://bids-specification.readthedocs.io/en/stable/04-modality-specific-files/05-task-events.html), a correct column name is 'trial_type', not 'stim_type'. Also, an emtpy trial name for the 'rest' period was problematic. So, I fixed these issues with the script below. \n",
    "\n",
    "```python\n",
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from cmath import nan\n",
    "import os\n",
    "import glob\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "path_root = sys.argv[1]\n",
    "path_events = os.path.join(path_root, '*', 'func', '*_events.tsv')\n",
    "\n",
    "# get all fieldmap files in the data-set:\n",
    "files_events = glob.glob(path_events)\n",
    "# loop over all event files:\n",
    "for file_path in files_events:\n",
    "    # read in the event file\n",
    "    events = pd.read_table(file_path)\n",
    "    # rename the column\n",
    "    events.rename(columns={\"stim_type\": \"trial_type\"}, inplace=True)\n",
    "    # fill empty trial type as REST\n",
    "    events[\"trial_type\"].replace(nan, 'REST', inplace=True)\n",
    "    # save the updated file\n",
    "    events.to_csv(file_path, sep=\"\\t\", index=False)\n",
    "    print(file_path, \" updated\")\n",
    "```\n",
    "\n",
    "#### README\n",
    "\n",
    "*\"TODO: Provide description for the dataset -- basic details about the study, possibly pointing to pre-registration (if public or embargoed)\"*\n",
    "\n",
    "See an example for the OpenNeuro version of this dataset https://openneuro.org/datasets/ds000117/versions/1.0.5/file-display/README"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate BIDS structure\n",
    "\n",
    "Does our newly created directory and file structure complies with the `BIDS` standart? We can check it with an [online BIDS validator](https://bids-standard.github.io/bids-validator/).\n",
    "\n",
    "We get some warnings about events custom columns that have no description. We can include events.json file that contains this information. For guidance see the BIDS specification https://bids-specification.readthedocs.io/en/stable/04-modality-specific-files/05-task-events.html\n",
    "\n",
    "Suspiciously long event: `sub-10_task-facerecognition_run-09_events.tsv`. Can add this information in the README file: *Owing to scanner error, Subject 10 only has 170 volumes in last run (Run 9) (hence the BIDS warning of some onsets in events.tsv file being later than the data)* \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Field Maps 'Intended For' field needs to be added\n",
    "\n",
    "For later pre-processing steps to work smoothly, we need to add `IntendedFor` field to fieldmap JASONs\n",
    "\n",
    "`step03_BIDS_add-IntendedFor.py` to link fieldmaps to functional scans.\n",
    "\n",
    "```python\n",
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "# ======================================================================\n",
    "# SCRIPT INFORMATION:\n",
    "# Add IntendedFor to Fieldmap JSON files\n",
    "# Adapted from LENNART WITTKUHN https://github.com/lnnrtwttkhn/highspeed-bids\n",
    "# ======================================================================\n",
    "# IMPORT RELEVANT PACKAGES\n",
    "# ======================================================================\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import stat\n",
    "import sys\n",
    "# ======================================================================\n",
    "# DEFINE PATHS\n",
    "# ======================================================================\n",
    "# to run type python3 bids-fieldmaps.py $PATH_ROOT\n",
    "path_root = sys.argv[1]\n",
    "path_fmap = os.path.join(path_root, '*', 'fmap', '*.json')\n",
    "path_func = os.path.join(path_root, '*', 'func', '*.nii.gz')\n",
    "# ======================================================================\n",
    "# UPDATE FIELDMAP JSON FILES\n",
    "# ======================================================================\n",
    "# get all fieldmap files in the data-set:\n",
    "files_fmap = glob.glob(path_fmap)\n",
    "# loop over all field-map files:\n",
    "for file_path in files_fmap:\n",
    "    # open the .json file of the fieldmap acquisition:\n",
    "    with open(file_path, 'r') as in_file:\n",
    "        json_info = json.load(in_file)\n",
    "    in_file.close()\n",
    "    # get the path to the session folder of a specific participant:\n",
    "    file_base = os.path.dirname(os.path.dirname(file_path))\n",
    "    # get the path to all functional acquisitions in that session:\n",
    "    files_func = glob.glob(os.path.join(file_base, 'func', '*bold.nii.gz'))\n",
    "    #session = os.path.basename(file_base)\n",
    "    #up_dirs = os.path.join(session, 'func')\n",
    "    up_dirs = 'func'\n",
    "    intended_for = [os.path.join(up_dirs, os.path.basename(file)) for file in files_func]\n",
    "    json_info[\"IntendedFor\"] = sorted(intended_for)\n",
    "    # change file permissions to read:\n",
    "    permissions = os.stat(file_path).st_mode\n",
    "    os.chmod(path=file_path, mode=permissions | stat.S_IWUSR)\n",
    "    # save updated fieldmap json-file:\n",
    "    with open(file_path, 'w') as out_file:\n",
    "        json.dump(json_info, out_file, indent=2, sort_keys=True)\n",
    "    out_file.close()\n",
    "    # change file permissions back to read-only:\n",
    "    os.chmod(path=file_path, mode=permissions)\n",
    "```\n",
    "\n",
    "`python3 step03_BIDS_add-IntendedFor.py /imaging/correia/dace/training/summer-school/Example_v02/FaceRecognition/data/bids`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional help on BIDS\n",
    "\n",
    "[BIDS for MRI: Structure and Conversion by Taylor Salo](https://osf.io/fbj5u) (video, 13:39)\n",
    "\n",
    "[Stanford BIDS Tutorial Series: HeuDiConv Walkthrough](https://reproducibility.stanford.edu/bids-tutorial-series-part-2a/)\n",
    "\n",
    "[Neurostars forum, BIDS tag](https://neurostars.org/tags/bids)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## PyBIDS\n",
    "\n",
    "`PyBids` is a Python module to interface with datasets conforming BIDS. See the [documentation](https://bids-standard.github.io/pybids/) and [paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7409983/) for more info. `PyBids` can be installed with `pip install pybids` command.\n",
    "\n",
    "**Here we will explore some of the functionality of pybids.layout.** The material is adapted from https://github.com/bids-standard/pybids/tree/master/examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from bids.layout import BIDSLayout\n",
    "from bids.tests import get_test_data_path\n",
    "\n",
    "ds_path = '/imaging/correia/dace/training/summer-school/Example_v03/FaceRecognition/data/bids'\n",
    "\n",
    "# Initialize the layout\n",
    "layout = BIDSLayout(ds_path)\n",
    "\n",
    "# Print some basic information about the layout\n",
    "layout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying the BIDSLayout\n",
    "The main method for querying `BIDSLayout` is `.get()`.\n",
    "\n",
    "If we call `.get()` with no additional arguments, we get back a list of all the BIDS files in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = layout.get()\n",
    "print(\"There are {} files in the layout.\".format(len(all_files)))\n",
    "print(\"\\nThe first 5 files are:\")\n",
    "all_files[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The returned object is a **Python list**. Each element in the list is a `BIDSFile` object. \n",
    "\n",
    "We can also get just filenames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layout.get(return_type='filename')[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also get such information as\n",
    "* all `subject` IDs\n",
    "* all `task` names\n",
    "* dataset `description`\n",
    "* the BOLD repetition time TR\n",
    "* how many `runs` there are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layout.get_subjects()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layout.get_tasks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layout.get_dataset_description()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layout.get_tr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regarding runs, it might be that there are varied number of runs accross participants. So, let's get runs for each participant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sID in layout.get_subjects(): \n",
    "    print(layout.get_runs(subject = sID))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering files by entities\n",
    "We can pass any BIDS-defined entities (keywords) to `.get()` method. For example, here's how we would retrieve all BOLD runs with `.nii.gz` extensions for subject `04`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve filenames of all BOLD runs for subject 01\n",
    "layout.get(subject='04', extension='nii.gz', suffix='bold', return_type='filename')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the entities are found in the names of BIDS files. For example `sub-01_task-facerecognition_run-01_bold.nii.gz` has entities: **subject** **task** **run** **suffix** **extension**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get the list of all availabe entities by `layout.get_entities()`.\n",
    "\n",
    "Here are a few of the most common entities:\n",
    "\n",
    "* `suffix`: The part of a BIDS filename just before the extension (e.g., 'bold', 'events', 'T1w', etc.).\n",
    "* `subject`: The subject label\n",
    "* `session`: The session label\n",
    "* `run`: The run index\n",
    "* `task`: The task name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layout.get_entities()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering by metadata\n",
    "Sometimes we want to search for files based not just on their names, but also based on metadata defined in JSON files. We can pass any key that occurs in any JSON file in our project as an argument to `.get()`. We can combine these with any number of core BIDS entities (like `subject`, `run`, etc.).\n",
    "\n",
    "For example, we want to retrieve `SpacingBetweenSlices` for all our subjects. And let's create a nice data frame of this information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "d = []\n",
    "for subject in layout.get_subjects():\n",
    "    d.append(\n",
    "        {\n",
    "            'subject': subject,\n",
    "            'spacing': layout.get_SpacingBetweenSlices(subject=subject, suffix='bold')\n",
    "        }\n",
    "    )\n",
    "df = pd.DataFrame(d)\n",
    "df = df.sort_values(by=['subject'])\n",
    "\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other `return_type` values\n",
    "We can also ask `get()` to return unique values (or IDs) of particular entities. For example, we want to know which subjects have at least one `T1w` file. We can request that information by setting `return_type='id'`. When using this option, we also need to specify a target entity (or metadata keyword) called `target`. This combination tells the `BIDSLayout` to return the unique values for the specified `target` entity. \n",
    "\n",
    "For example, in the next example, we ask for all of the unique subject IDs that have at least one file with a `phasediff` suffix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask get() to return the ids of subjects that have phasediff (fieldmap_ files\n",
    "layout.get(return_type='id', target='subject', suffix='phasediff')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If our `target` is a BIDS entity that corresponds to a particular directory in the BIDS specification (e.g., `subject` or `session`) we can also use `return_type='dir'` to get all matching subdirectories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layout.get(return_type='dir', target='subject')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `BIDSFile`\n",
    "When you call `.get()` on a `BIDSLayout`, the default returned values are objects of class `BIDSFile`. A `BIDSFile` is a lightweight container for individual files in a BIDS dataset. It provides easy access to a variety of useful attributes and methods. Let's take a closer look. First, let's pick a random file from our existing `layout`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick the 7th file in the dataset\n",
    "bf = layout.get()[7]\n",
    "# Print it\n",
    "bf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some of the attributes and methods available to us in a `BIDSFile` (note that some of these are only available for certain subclasses of `BIDSFile`; e.g., you can't call `get_image()` on a `BIDSFile` that doesn't correspond to an image file!):\n",
    "* `.path`: The full path of the associated file\n",
    "* `.filename`: The associated file's filename (without directory)\n",
    "* `.dirname`: The directory containing the file\n",
    "* `.get_entities()`: Returns information about entities associated with this `BIDSFile` (optionally including metadata)\n",
    "* `.get_image()`: Returns the file contents as a nibabel image (only works for image files)\n",
    "* `.get_df()`: Get file contents as a pandas DataFrame (only works for TSV files)\n",
    "* `.get_metadata()`: Returns a dictionary of all metadata found in associated JSON files\n",
    "* `.get_associations()`: Returns a list of all files associated with this one in some way\n",
    "\n",
    "Let's see some of these in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print all the entities associated with this file, and their values\n",
    "bf.get_entities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print all the metadata associated with this file\n",
    "bf.get_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can the union of both of the above in one shot like this\n",
    "bf.get_entities(metadata='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are all the files associated with our target file in some way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bf.get_associations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.get_image()`: Returns the file contents as a `nibabel` image (only works for image files). We can then display the image, for example, using `OrthoSlicer3D` which requires `matplotlib`.   \n",
    "\n",
    "**Note:** When using `orthoview()` in notebook, don't forget to close figures afterward again or use%matplotlib inline again, otherwise, you cannot plot any other figures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "\n",
    "bf.get_image().orthoview()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `.tsv` files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In cases where a file has a `.tsv.gz` or `.tsv` extension, it will automatically be created as a `BIDSDataFile`, and we can easily grab the contents as a `DataFrame`.\n",
    "\n",
    "Let's look at the first `events` file from our layout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first events file\n",
    "evfile = layout.get(suffix='events')[0]\n",
    "\n",
    "# Get contents as a DataFrame and show the first few rows\n",
    "df = evfile.get_df()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the `participants` information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participants = layout.get(suffix='participants', extension='tsv')[0]\n",
    "participants.get_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filename parsing\n",
    "Let's say you have a filename, and you want to manually extract BIDS entities from it. The parse_file_entities method provides the facility:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layout.parse_file_entities('some_path_to_bids_file/sub-04_task-facerecognition_run-01_bold.nii.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can do the same for `BIDSFile` object that we defined earlier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layout.parse_file_entities(bf.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Path construction\n",
    "You may want to create valid BIDS filenames for files that are new or hypothetical that would sit within your BIDS project. This is useful when you know what entity values you need to write out to, but don’t want to deal with looking up the precise BIDS file-naming syntax. In the example below, imagine we’ve created a new file containing stimulus presentation information, and we want to save it to a `.tsv.gz` file, per the BIDS naming conventions. All we need to do is define a dictionary with the name components, and build_path takes care of the rest (including injecting sub-directories!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = {\n",
    "    'subject': '01',\n",
    "    'run': '02',\n",
    "    'task': 'facerecognition',\n",
    "    'suffix': 'bold'\n",
    "}\n",
    "\n",
    "layout.build_path(entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep in mind that `_` and `-` have special meaning in BIDS specification. E.g., you can't name your task `face-recognition`, that would not be 'spec-compliant' and would end in an error! However, if you add `validate=False`, you can get away with it (i'e', `layout.build_path(entities, validate=False)`). \n",
    "\n",
    "You can also use `build_path` in more sophisticated ways by defining your own set of matching templates that cover cases not supported by BIDS out of the box. For example, suppose you want to create a template for naming a new `stat` file. You could do something like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the pattern to build out of the components passed in the dictionary\n",
    "pattern = \"sub-{subject}[_ses-{session}]_task-{task}[_run-{run}]_{suffix}.nii.gz\"\n",
    "\n",
    "entities = {\n",
    "    'subject': '01',\n",
    "    'run': '02',\n",
    "    'task': 'facerecognition',\n",
    "    'suffix': 'stat'\n",
    "}\n",
    "\n",
    "# Notice we pass the new pattern as the second argument\n",
    "layout.build_path(entities, pattern, validate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting a `BIDSLayout` to a pandas `Dataframe`\n",
    "If you want a summary of all the files in your `BIDSLayout`, but don't want to have to iterate `BIDSFile` objects and extract their entities, you can get a nice bird's-eye view of your dataset using the `to_df()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the layout to a pandas dataframe\n",
    "df = layout.to_df()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also include metadata in the result if we like (which may blow up our `DataFrame` if we have a large dataset). Note that in this case, most of our cells will have missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = layout.to_df(metadata=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report generation\n",
    "`PyBIDS` also allows you to automatically create data acquisition reports based on the available `image` and `meta-data` information. This enables a new level of standardisation and transparency. FAIR-ness, meta-analyses, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the BIDSReport function from the reports submodule\n",
    "from bids.reports import BIDSReport"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we only need to apply the `BIDSReport` function to our `layout` and generate our report. \n",
    "\n",
    "In your example dataset the report might run into error as the dataset is incomplete. The code below deals with that case. But a successfull report would look something like this:\n",
    "\n",
    ">In session None, MR data were acquired using a 3-Tesla Siemens TrioTim MRI scanner.\n",
    "\tOne run of T1-weighted SP\\MP\\OSP GR\\IR (GR\\IR) single-echo structural MRI data were collected (256 slices; repetition time, TR=2250ms; echo time, TE=2.98ms; flip angle, FA=9<deg>; field of view, FOV=192x256mm; matrix size=192x256; voxel size=1x1x1mm).\n",
    "\tA spoiled gradient recalled (GR) field map (phase encoding: anterior to posterior; 33 slices in interleaved ascending order; repetition time, TR=400ms; echo time 1 / 2, TE1/2=5.197.65ms; flip angle, FA=60<deg>; field of view, FOV=192x192mm; matrix size=64x64; voxel size=3x3x3.75mm) was acquired for the first, second, third, fourth, fifth, sixth, seventh, eighth, and ninth runs of the facerecognition BOLD scan.\n",
    "\tNine runs of facerecognition segmented k-space echo planar (EP) single-echo fMRI data were collected (33 slices in interleaved ascending order; repetition time, TR=2000ms; echo time, TE=30ms; flip angle, FA=78<deg>; field of view, FOV=192x192mm; matrix size=64x64; voxel size=3x3x3.75mm). Run duration was 6:56 minutes, during which 208 volumes were acquired.\n",
    "\n",
    ">Dicoms were converted to NIfTI-1 format using dcm2niix (v1.0.20220720). This section was (in part) generated automatically using pybids (0.15.3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Initialize a report for the dataset\n",
    "report = BIDSReport(layout)\n",
    "\n",
    "# Method generate returns a Counter of unique descriptions across subjects\n",
    "try:\n",
    "    descriptions = report.generate()\n",
    "    pub_description = descriptions.most_common()[0][0]\n",
    "    print(pub_description)\n",
    "except IndexError:\n",
    "    print('Sorry, it seems that the dataset is not complete and report cannot be generated.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "254.333px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
